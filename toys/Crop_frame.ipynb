{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# get the current object detection and crop bbox to keep the ration 3:4\n",
    "def get_bbox_cropp_keep_ration(bbox):\n",
    "    bbox2 = np.array([0,0,0,0])    \n",
    "\n",
    "    # need to set the scale to go from Sighthound resolution to original\n",
    "    x_scale = 4.5\n",
    "    y_scale = 4.53\n",
    "    bbox[0] = bbox[0]*x_scale\n",
    "    bbox[1] = bbox[1]*y_scale\n",
    "    bbox[2] = bbox[2]*x_scale\n",
    "    bbox[3] = bbox[3]*y_scale\n",
    "    width   = bbox[2]-bbox[0]\n",
    "    x_center= bbox[0]+width/2\n",
    "    height  = bbox[3]-bbox[1]\n",
    "    y_center= bbox[1]+height/2\n",
    "    # normalization for Faster-RCNN\n",
    "    fix_width = 500\n",
    "    fix_height = 375\n",
    "    #print([width,height,bbox])\n",
    "    #print([x_center,y_center])\n",
    "    # if the bbox is on the edge of the image\n",
    "    if x_center < fix_width/2:\n",
    "        x_center = fix_width/2\n",
    "\n",
    "    if y_center < fix_height/2:\n",
    "        y_center = fix_height/2\n",
    "\n",
    "    if (1920-x_center) < fix_width/2:\n",
    "        x_center = 1920-fix_width/2\n",
    "\n",
    "\n",
    "    if (1080-y_center) < fix_height/2:\n",
    "        y_center = 1080-fix_height/2\n",
    "\n",
    "    # normalize      \n",
    "    if width>height:\n",
    "        expected_height = width*0.75\n",
    "        expected_width = width\n",
    "    else:\n",
    "        expected_width = height/0.75\n",
    "        expected_height = height\n",
    "        \n",
    "    #print([x_center,y_center])\n",
    "    #print([expected_width,expected_height])\n",
    "    # extend the bbox to keep the ratio between 500x375\n",
    "    bbox2[0] = x_center-expected_width/2\n",
    "    bbox2[1] = y_center-expected_height/2\n",
    "    bbox2[2] = x_center+expected_width/2\n",
    "    bbox2[3] = y_center+expected_height/2\n",
    "    #print(bbox2)\n",
    "    # increase size of bbox2\n",
    "    bbox_scale = 0.3\n",
    "    bbox2[0] = max(0,bbox2[0]-fix_width*bbox_scale)\n",
    "    bbox2[1] = max(0,bbox2[1]-fix_height*bbox_scale)\n",
    "    bbox2[2] = min(1920,bbox2[2]+fix_width*bbox_scale)\n",
    "    bbox2[3] = min(1080,bbox2[3]+fix_height*bbox_scale)\n",
    "    return bbox2\n",
    "\n",
    "def get_bbox_exact_cropp(bbox):\n",
    "    bbox2 = np.array([0,0,0,0])    \n",
    "\n",
    "    # need to set the scale to go from Sighthound resolution to original\n",
    "    x_scale = 4.5\n",
    "    y_scale = 4.53\n",
    "    bbox[0] = bbox[0]*x_scale\n",
    "    bbox[1] = bbox[1]*y_scale\n",
    "    bbox[2] = bbox[2]*x_scale\n",
    "    bbox[3] = bbox[3]*y_scale\n",
    "    return bbox\n",
    "\n",
    "\n",
    "def crop_image(image_path, image_name, bbox, id, cropfile, outpath):\n",
    "\n",
    "    im_file = os.path.join(image_path, image_name)\n",
    "    im = Image.open(im_file)  \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "\n",
    "    bbox2 = get_bbox_exact_cropp(bbox)\n",
    "    outFile =  outpath  + str(id) + '_' + image_name\n",
    "    im2 = im.crop((bbox2))\n",
    "    im2.save(outFile)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    with open(cropfile, 'a') as text_file:\n",
    "        print(\"{},{},{},{},{}\".format(str(id) + '_' + image_name,bbox2[0],bbox2[1],bbox2[2],bbox2[3]), file=text_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# crop the image based on given BBOX\n",
    "\n",
    "in_dir = 'z:/OC_RESINET/ResiIndoor/Img_orig/'\n",
    "\n",
    "annotation_file = 'z:/OC_RESINET/ResiIndoor/CSV/ResiIndoor_annotations_output_all.csv'\n",
    "\n",
    "out_dir = in_dir + 'Annotation_Crop/'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "cropfile = out_dir + 'img_list_bbox.csv'\n",
    "if os.path.exists(cropfile):\n",
    "    os.remove(cropfile)\n",
    "\n",
    "\n",
    "with open(annotation_file, 'r') as file:\n",
    "    line = file.readline()\n",
    "    for line in file:\n",
    "        line = str(line)\n",
    "        image_name,id,x,y,u,v,s = line.split(',')\n",
    "        bbox = np.array([float(x),float(y),float(u),float(v)])\n",
    "        #if image_name[-8:-4] == '1081':\n",
    "                #print(i)\n",
    "        crop_image(in_dir, image_name, bbox, id, cropfile, out_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
